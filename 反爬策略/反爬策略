1、网站为什么要进行反爬？
	1、数据是有价值的，保护自身服务器资源，识别出爬虫程序，限制恶意访问请求
2、网站如何识别爬虫
	爬虫程序和我们使用的浏览器，或者app都是客户端程序，网站反爬本质上是需要找出真正人类，和爬虫程序的区别
	1、通过请求信息的区别，
		headers  
			ua
			referer
		cookies
			登录
			验证码
		特定请求参数 例如token
	2、用户行为识别
		单位时间的请求频率
			ip
			ua
			cookies
		检测用户行为
			是否有鼠标移动
			是否有移动复合人类行为特征
		3、频繁/定期更换反爬措施

3、网站措施
	1、直接拒绝爬虫请求
	2、返回验证码，
	3、返回真实数据和伪数据混合

4、反反爬
	基本策略
		1、控制请求效率
		2、破解困难较大，适当牺牲一些自动化，如手动打码
	提高效率
	ua+cookies+ip模拟多个客户端发送请求

	程序完全自动化运行问题
	爬虫程序自动生成加密参数
	爬虫自动化处理验证码
	
	
5、ua
	ua池，fake_useagent

6、ip池
	
	